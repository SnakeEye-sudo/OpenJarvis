# LLM Integration (Stub)

Connectors planned:
- OpenAI, Anthropic, Azure OpenAI, Ollama (local), Hugging Face Inference

Standard interface:
- generate(prompt, context) -> text
- stream_generate(prompt, context) -> tokens

Notes on rate limiting, retries, and safety filters.
